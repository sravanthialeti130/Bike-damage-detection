{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5f2b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: geocoder in c:\\users\\sravanthi\\appdata\\roaming\\python\\python39\\site-packages (1.38.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from geocoder) (8.0.4)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from geocoder) (0.18.2)\n",
      "Requirement already satisfied: ratelim in c:\\users\\sravanthi\\appdata\\roaming\\python\\python39\\site-packages (from geocoder) (0.1.6)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from geocoder) (2.27.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from geocoder) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->geocoder) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ratelim->geocoder) (5.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->geocoder) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->geocoder) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->geocoder) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->geocoder) (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install geocoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399c45e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status code Unknown from http://ipinfo.io/json: ERROR - HTTPConnectionPool(host='ipinfo.io', port=80): Max retries exceeded with url: /json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000016DF22184C0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "C:\\Users\\Sravanthi\\AppData\\Local\\Temp\\ipykernel_5772\\1377923007.py:64: RuntimeWarning: invalid value encountered in sqrt\n",
      "  gradient_magnitude = np.sqrt(gradient_x*2 + gradient_y*2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import geocoder\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Reading label name from obj.names file\n",
    "class_name = ['damaged']\n",
    "with open(os.path.join(\"Downloads\", r\"C:\\Users\\Sravanthi\\Downloads\\object.names.txt\"), 'r') as f:\n",
    "    class_name = [cname.strip() for cname in f.readlines()]\n",
    "\n",
    "# Importing model weights and config file\n",
    "# Defining the model parameters\n",
    "net1 = cv2.dnn.readNet(r'C:\\Users\\Sravanthi\\Downloads\\yolov4-tiny.weights', r'C:\\Users\\Sravanthi\\Downloads\\yolov4-tiny.cfg')\n",
    "net1.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net1.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16)\n",
    "model1 = cv2.dnn_DetectionModel(net1)\n",
    "model1.setInputParams(size=(416, 416), scale=1/255, swapRB=True)  # Adjust input size based on the YOLOv4-tiny configuration\n",
    "\n",
    "# Defining the video source (0 for camera or file name for video)\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\Sravanthi\\Downloads\\WhatsApp Video 2023-09-11 at 15.24.53.mp4\")\n",
    "width = cap.get(3)\n",
    "height = cap.get(4)\n",
    "result = cv2.VideoWriter(r\"C:\\Users\\Sravanthi\\Downloads\\result.avi\",\n",
    "                        cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                        10, (416, 416))  # Adjusted width and height\n",
    "\n",
    "# Defining parameters for result saving and get coordinates\n",
    "# Defining initial values for some parameters in the script\n",
    "g = geocoder.ip('me')\n",
    "result_path = \"bike_coordinates\"\n",
    "starting_time = time.time()\n",
    "Conf_threshold = 0.5\n",
    "NMS_threshold = 0.4\n",
    "frame_counter = 0\n",
    "i = 0\n",
    "b = 0\n",
    "skip_frames = 3  # Process every 3rd frame\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    #create a copy of the frame for displaying the original video\n",
    "    original_frame = frame.copy()\n",
    "    \n",
    "    # Convert the frame to LAB color space\n",
    "    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Split the LAB image into L, A, and B channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply color thresholding based on the A and B channels\n",
    "    # Adjust the threshold values to capture the damaged regions based on color\n",
    "    color_mask = cv2.inRange(a, 100, 200) & cv2.inRange(b, 100, 200)\n",
    "\n",
    "    # Apply texture analysis using the L channel\n",
    "    # Apply a Gaussian filter to smooth the image\n",
    "    l_blurred = cv2.GaussianBlur(l, (5, 5), 0)\n",
    "\n",
    "    # Compute the gradient magnitude using the Sobel operator on the smoothed L channel\n",
    "    gradient_x = cv2.Sobel(l_blurred, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    gradient_y = cv2.Sobel(l_blurred, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitude = np.sqrt(gradient_x*2 + gradient_y*2)\n",
    "\n",
    "    # Normalize the gradient magnitude to the range [0, 255]\n",
    "    gradient_magnitude = cv2.normalize(gradient_magnitude, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "    # Apply texture thresholding based on the gradient magnitude\n",
    "    # Adjust the threshold value to capture the damaged regions based on texture\n",
    "    texture_mask = cv2.inRange(gradient_magnitude, 50, 255)\n",
    "\n",
    "    # Combine the color and texture masks\n",
    "    mask = cv2.bitwise_and(color_mask, texture_mask)\n",
    "\n",
    "    # Find contours in the mask to detect damaged areas\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Set the threshold area to filter out small or large areas\n",
    "    threshold_area = 1000  # Adjust this value based on your requirements\n",
    "\n",
    "    # Calculate the total area of the bike\n",
    "    bike_area = cv2.countNonZero(mask)\n",
    "\n",
    "    # Iterate over the contours and identify the damaged areas\n",
    "    damage_area = 0\n",
    "    for contour in contours:\n",
    "        # Filter contours based on area or shape properties to detect damaged areas\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > threshold_area:\n",
    "            # Find the bounding box of the damaged area\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Draw a rectangle around the damaged area\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            # Add the name of the damaged area near its rectangle\n",
    "            cv2.putText(frame, \"Damaged\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Increment the damage area\n",
    "            damage_area += area\n",
    "\n",
    "    # Calculate the percentage of damage\n",
    "    damage_percentage = (damage_area / bike_area) * 100\n",
    "\n",
    "    # Draw the text for the damage percentage on top of the frame\n",
    "    cv2.putText(frame, f\"Damage: {damage_percentage:.2f}%\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    concatenated_frames = np.hstack((original_frame,frame))\n",
    "\n",
    "    # Display the frame with the detected damaged areas and the damage percentage\n",
    "    cv2.imshow(\"Video Frame | original vs Damaged\", concatenated_frames)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b27aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the bike image\n",
    "original_image = cv2.imread(r\"C:\\\\Users\\\\Sravanthi\\\\Downloads\\\\123.jpeg\")\n",
    "image = original_image.copy()\n",
    "\n",
    "# Reading label names from obj.names file\n",
    "with open(os.path.join(\"Downloads\", r\"C:\\Users\\Sravanthi\\Downloads\\object.names.txt\"), 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "# Importing model weights and config file for object detection\n",
    "net = cv2.dnn.readNet(r'C:\\Users\\Sravanthi\\Downloads\\yolov4-tiny.weights', r'C:\\Users\\Sravanthi\\Downloads\\yolov4-tiny.cfg')\n",
    "model = cv2.dnn_DetectionModel(net)\n",
    "model.setInputParams(scale=1 / 255, size=(416, 416), swapRB=True)\n",
    "\n",
    "# Detect objects in the image\n",
    "classIds, scores, boxes = model.detect(original_image, confThreshold=0.6, nmsThreshold=0.4)\n",
    "\n",
    "# Initialize variables for bike damage detection\n",
    "damage_area = 0\n",
    "bike_area = 0\n",
    "\n",
    "# Iterate over the detected objects\n",
    "for (classId, score, box) in zip(classIds, scores, boxes):\n",
    "    if classes[int(classId[0])] == \"damaged\":\n",
    "        # Draw bounding box for damaged object\n",
    "        cv2.rectangle(image, (box[0], box[1]), (box[0] + box[2], box[1] + box[3]), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Update bike area\n",
    "        bike_area += (box[2] * box[3])\n",
    "\n",
    "        # Crop the damaged region from the image\n",
    "        damaged_region = original_image[int(box[1]):int(box[1] + box[3]), int(box[0]):int(box[0] + box[2])]\n",
    "\n",
    "# Convert the image to LAB color space\n",
    "lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Split the LAB image into L, A, and B channels\n",
    "l, a, b = cv2.split(lab)\n",
    "\n",
    "# Apply color thresholding based on the A and B channels\n",
    "# Adjust the threshold values to capture the damaged regions based on color\n",
    "color_mask = cv2.inRange(a, 100, 200) & cv2.inRange(b, 100, 200)\n",
    "\n",
    "# Apply texture analysis using the L channel\n",
    "# Apply a Gaussian filter to smooth the image\n",
    "l_blurred = cv2.GaussianBlur(l, (5, 5), 0)\n",
    "\n",
    "# Compute the gradient magnitude using the Sobel operator on the smoothed L channel\n",
    "gradient_x = cv2.Sobel(l_blurred, cv2.CV_64F, 1, 0, ksize=3)\n",
    "gradient_y = cv2.Sobel(l_blurred, cv2.CV_64F, 0, 1, ksize=3)\n",
    "gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "# Normalize the gradient magnitude to the range [0, 255]\n",
    "gradient_magnitude = cv2.normalize(gradient_magnitude, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "# Apply texture thresholding based on the gradient magnitude\n",
    "# Adjust the threshold value to capture the damaged regions based on texture\n",
    "texture_mask = cv2.inRange(gradient_magnitude, 50, 255)\n",
    "\n",
    "# Combine the color and texture masks\n",
    "mask = cv2.bitwise_and(color_mask, texture_mask)\n",
    "\n",
    "# Find contours in the mask to detect damaged areas\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Set the threshold area to filter out small or large areas\n",
    "threshold_area = 1000  # Adjust this value based on your requirements\n",
    "\n",
    "# Calculate the total area of the bike\n",
    "bike_area = cv2.countNonZero(mask)\n",
    "\n",
    "# Assign a value to 'damage_percentage' before using it\n",
    "\n",
    "\n",
    "# Iterate over the contours and identify the damaged areas\n",
    "damage_area = 0\n",
    "for contour in contours:\n",
    "    # Filter contours based on area or shape properties to detect damaged areas\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area > threshold_area:\n",
    "        # Find the bounding box of the damaged area\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Draw a rectangle around the damaged area\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        damage_percentage = 75.0\n",
    "        # Add the name of the damaged area near its rectangle\n",
    "        cv2.putText(image, f\"Damaged: {damage_percentage:.2f}%\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        # Increment the damage area\n",
    "        damage_area += area\n",
    "\n",
    "# Calculate the percentage of damage\n",
    "damage_percentage = (damage_area / bike_area) * 100\n",
    "\n",
    "# Draw the text for the damage percentage on top of the image\n",
    "cv2.putText(image, f\"Damage: {damage_percentage:.2f}%\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "# Create an image with double width to display both original and damaged images side by side\n",
    "concatenated_image = np.hstack((original_image, image))\n",
    "\n",
    "# Display the bike image with the detected damaged areas and the damage percentage\n",
    "cv2.imshow(\"Original Image | Bike Damage Detection\", concatenated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5455749e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fe5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
